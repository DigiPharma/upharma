#=====================================================================
MAIN FUNCTION WITH PDX-FOCUSED CROSS-VALIDATION
#=====================================================================

def main():
    start_time = time.time()

    # Try to mount Google Drive for Colab
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print("Google Drive mounted successfully")
        using_colab = True
    except (ImportError, ModuleNotFoundError):
        print("Not running in Colab or drive module not available")
        using_colab = False

    # Define output directories - SAVE TO GOOGLE DRIVE
    if using_colab:
        # Change this base path to your desired Google Drive folder
        base_drive_path = '/content/drive/MyDrive/PDX_Analysis_Results_New042025/'
    else:
        base_drive_path = './'  # Local path if not using Colab

    output_dirs = {
        'model_dir': os.path.join(base_drive_path, 'xgboost_pdx_cv'),
        'plots_dir': os.path.join(base_drive_path, 'plots_pdf'),
        'data_dir': os.path.join(base_drive_path, 'data_csv')
    }

    # Create all directories
    for dir_name, dir_path in output_dirs.items():
        create_output_directory(dir_path)

    # File path - Try to load from Google Drive if available
    if using_colab:
        # Change this path to your input file location on Drive
        file_path = '/content/drive/MyDrive/DMF_Pharmacotyping/data_combined_all_032725.csv'
    else:
        file_path = 'data_combined_all.csv'  # Local path

    # Load the data
    try:
        df = pd.read_csv(file_path)
        print(f"Dataset loaded with shape: {df.shape}")
    except FileNotFoundError:
        print(f"File not found at: {file_path}")
        return

    df['Group'] = df['Group'].astype(str)
    # Define cell line samples based on information
    cell_line_names = ['CEM', 'HSB', 'KOPT', 'RPMI8402', 'LOUCY', 'MOLT4', 'DND41']

    # Apply the function to determine sample types
    df['Sample_Type'] = df['Group'].apply(lambda x: determine_sample_type(x, cell_line_names))

    # Display counts of each sample type
    print("\nSample type distribution:")
    print(df['Sample_Type'].value_counts())

    # Filter to only PDX samples
    pdx_df = df[df['Sample_Type'] == 'PDX'].copy()
    print(f"\nPDX samples selected: {pdx_df.shape[0]} rows")

    # Get unique PDX groups
    pdx_groups = pdx_df['Group'].astype(str).unique()
    print(f"\nFound {len(pdx_groups)} unique PDX groups: {', '.join(pdx_groups)}")

    if len(pdx_groups) != 14:
        print(f"WARNING: Expected 14 PDX groups but found {len(pdx_groups)}. Will continue with available groups.")

    #-------------------------------------------------------------
    # ENHANCED FEATURE ENGINEERING
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ENHANCED FEATURE ENGINEERING")
    print("="*80)

    # Handle missing and infinite values
    pdx_df.replace([np.inf, -np.inf], np.nan, inplace=True)

    # Only handle missing values for categorical columns, leave numeric NaNs for XGBoost
    categorical_cols = pdx_df.select_dtypes(exclude=np.number).columns
    for col in categorical_cols:
        if pdx_df[col].isnull().any():
            pdx_df[col].fillna('Unknown', inplace=True)

    # Basic ratio features (keeping original implementation)
    pdx_df['pLCK_to_LCK_ratio'] = np.divide(
        pdx_df['Intensity_MeanIntensity_pLCK'].values,
        pdx_df['Intensity_MeanIntensity_LCK'].values,
        out=np.zeros_like(pdx_df['Intensity_MeanIntensity_pLCK'].values, dtype=float),
        where=pdx_df['Intensity_MeanIntensity_LCK'].values!=0
    )
    pdx_df['pBCL2_to_BCL2_ratio'] = np.divide(
        pdx_df['Intensity_MeanIntensity_pBCL2'].values,
        pdx_df['Intensity_MeanIntensity_BCL_2'].values,
        out=np.zeros_like(pdx_df['Intensity_MeanIntensity_pBCL2'].values, dtype=float),
        where=pdx_df['Intensity_MeanIntensity_BCL_2'].values!=0
    )

    # Enhanced features - log transformations (adding small constant to avoid log(0))
    pdx_df['log_pLCK'] = np.log1p(pdx_df['Intensity_MeanIntensity_pLCK'])
    pdx_df['log_LCK'] = np.log1p(pdx_df['Intensity_MeanIntensity_LCK'])
    pdx_df['log_pBCL2'] = np.log1p(pdx_df['Intensity_MeanIntensity_pBCL2'])
    pdx_df['log_BCL2'] = np.log1p(pdx_df['Intensity_MeanIntensity_BCL_2'])
    # Log ratios (can capture different patterns than direct ratios)
    pdx_df['log_pLCK_to_LCK_ratio'] = pdx_df['log_pLCK'] - pdx_df['log_LCK']
    pdx_df['log_pBCL2_to_BCL2_ratio'] = pdx_df['log_pBCL2'] - pdx_df['log_BCL2']

    # Square and square root transformations to capture non-linear relationships
    pdx_df['pLCK_squared'] = np.square(pdx_df['Intensity_MeanIntensity_pLCK'])
    pdx_df['pBCL2_squared'] = np.square(pdx_df['Intensity_MeanIntensity_pBCL2'])
    pdx_df['pLCK_sqrt'] = np.sqrt(np.maximum(0, pdx_df['Intensity_MeanIntensity_pLCK']))
    pdx_df['pBCL2_sqrt'] = np.sqrt(np.maximum(0, pdx_df['Intensity_MeanIntensity_pBCL2']))

    # Z-scores for pLCK and pBCL2 within each PDX group
    for group in pdx_df['Group'].unique():
        group_mask = pdx_df['Group'] == group
        if sum(group_mask) > 1:  # Only standardize if we have multiple samples
            pdx_df.loc[group_mask, 'pLCK_zscore'] = safe_standardize(pdx_df.loc[group_mask, 'Intensity_MeanIntensity_pLCK'])
            pdx_df.loc[group_mask, 'pBCL2_zscore'] = safe_standardize(pdx_df.loc[group_mask, 'Intensity_MeanIntensity_pBCL2'])

    # Fill any missing z-scores with 0 (representing the mean)
    if 'pLCK_zscore' not in pdx_df.columns:
        pdx_df['pLCK_zscore'] = 0
    else:
        pdx_df['pLCK_zscore'].fillna(0, inplace=True)

    if 'pBCL2_zscore' not in pdx_df.columns:
        pdx_df['pBCL2_zscore'] = 0
    else:
        pdx_df['pBCL2_zscore'].fillna(0, inplace=True)
    # Create interaction features between key proteins and important shape features
    # First, identify top shape features that might interact with protein markers
    shape_features = [col for col in pdx_df.columns if 'AreaShape' in col]

    # Select a subset of shape features to avoid feature explosion
    key_shape_features = [
        'AreaShape_Area', 'AreaShape_Perimeter',
        'AreaShape_FormFactor', 'AreaShape_Eccentricity',
        'AreaShape_Solidity', 'AreaShape_Extent'
    ]

    # Filter to only use shape features that exist in the data
    key_shape_features = [f for f in key_shape_features if f in pdx_df.columns]

    # Create interaction features between key proteins and shape features
    for shape_feat in key_shape_features:
        if shape_feat in pdx_df.columns:
            # For pLCK
            pdx_df[f'pLCK_x_{shape_feat}'] = pdx_df['Intensity_MeanIntensity_pLCK'] * pdx_df[shape_feat]
            pdx_df[f'pLCK_ratio_x_{shape_feat}'] = pdx_df['pLCK_to_LCK_ratio'] * pdx_df[shape_feat]

            # For pBCL2
            pdx_df[f'pBCL2_x_{shape_feat}'] = pdx_df['Intensity_MeanIntensity_pBCL2'] * pdx_df[shape_feat]
            pdx_df[f'pBCL2_ratio_x_{shape_feat}'] = pdx_df['pBCL2_to_BCL2_ratio'] * pdx_df[shape_feat]

    # Replace any infinity values with NaN
    pdx_df.replace([np.inf, -np.inf], np.nan, inplace=True)
    # Define clean feature sets for each drug (no cross-contamination)
    lck_features_clean = [col for col in pdx_df.columns if 'LCK' in col.upper() and 'BCL' not in col.upper()]

    # Enhanced LCK features - only include those related to LCK not BCL2
    lck_enhanced_features_clean = [
        col for col in [
            'log_pLCK', 'log_LCK', 'log_pLCK_to_LCK_ratio',
            'pLCK_squared', 'pLCK_sqrt', 'pLCK_zscore', 'pLCK_to_LCK_ratio'
        ] if col in pdx_df.columns
    ]

    # LCK interaction features - only those related to LCK not BCL2
    lck_interaction_features_clean = [
        col for col in pdx_df.columns
        if ('pLCK_x_' in col or 'pLCK_ratio_x_' in col) and 'BCL' not in col.upper()
    ]

    # BCL2/pBCL2 features and shape features for Venetoclax - exclude LCK features
    bcl2_features_clean = [col for col in pdx_df.columns if ('BCL' in col.upper() or 'pBCL2' in col) and 'LCK' not in col.upper()]

    # Enhanced BCL2 features - only include those related to BCL2 not LCK
    bcl2_enhanced_features_clean = [
        col for col in [
            'log_pBCL2', 'log_BCL2', 'log_pBCL2_to_BCL2_ratio',
            'pBCL2_squared', 'pBCL2_sqrt', 'pBCL2_zscore', 'pBCL2_to_BCL2_ratio'
        ] if col in pdx_df.columns
    ]

    # BCL2 interaction features - only those related to BCL2 not LCK
    bcl2_interaction_features_clean = [
        col for col in pdx_df.columns
        if ('pBCL2_x_' in col or 'pBCL2_ratio_x_' in col) and 'LCK' not in col.upper()
    ]
    # Shape features remain the same for both
    shape_features = [col for col in pdx_df.columns if 'AreaShape' in col]

    # Final clean feature sets for each drug (no cross-contamination)
    dasatinib_features = list(set(lck_features_clean + lck_enhanced_features_clean + lck_interaction_features_clean + shape_features))
    from collections import Counter
    dups = [item for item, count in Counter(dasatinib_features).items() if count > 1]
    if dups:
        print(f"WARNING: Duplicate column names in Dasatinib features: {dups}")

    bcl2_in_dasatinib = [f for f in dasatinib_features if 'BCL' in f.upper() or 'pBCL2' in f]
    if bcl2_in_dasatinib:
        print(f"WARNING: BCL2-related features found in Dasatinib features: {bcl2_in_dasatinib}")
        print("Removing these BCL2-related features from Dasatinib feature set")
        dasatinib_features = [f for f in dasatinib_features if f not in bcl2_in_dasatinib]
        print(f"Updated Dasatinib feature count: {len(dasatinib_features)}")

    print(f"\nNumber of features for Dasatinib prediction (after cleaning): {len(dasatinib_features)}")
    print(f"Number of features for Venetoclax prediction (after cleaning): {len(venetoclax_features)}")

    # Print a few examples of each feature set to verify
    print("\nSample Dasatinib features:")
    for feat in sorted(dasatinib_features)[:10]:
        print(f"  - {feat}")

    print("\nSample Venetoclax features:")
    for feat in sorted(venetoclax_features)[:10]:
        print(f"  - {feat}")
#-------------------------------------------------------------
    # DATA SPLITTING FOR PDX ROTATIONAL CROSS-VALIDATION
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("PDX ROTATIONAL CROSS-VALIDATION SETUP")
    print("="*80)

    # Define the sampling strategy for PDX groups for both drugs separately

    # Make sure we have enough PDX groups
    if len(pdx_groups) < 14:
        print(f"WARNING: Not enough PDX groups (found {len(pdx_groups)}, need 14). Will adjust rotation accordingly.")

    # Define custom PDX rotations for both drugs based on the provided information
    print("\nManually setting up predefined PDX rotations for each drug...")

    # Define Dasatinib rotations with actual PDX group names
    dasatinib_rotations = [
          {
              'train': np.array(['SJ65', 'SJ49', 'SJ53', 'SJ52', '1054', '145', '741', '748', '4406']),
              'val': np.array(['SJ7', '4426']),
              'test': np.array(['758', '2176', '4404'])
          },
          {
              'train': np.array(['SJ65', 'SJ49', 'SJ52', '4426', '4404', '4406', '741', '758', '2176']),
              'val': np.array(['145', '748']),
              'test': np.array(['SJ7', 'SJ53', '1054'])
          },
          {
              'train': np.array(['SJ65', 'SJ53', '1054', '4404', 'SJ49', '748', '758', '2176']),
              'val': np.array(['SJ7', '741']),
              'test': np.array(['145', '4406', 'SJ52','4426'])
          },
          {
              'train': np.array(['SJ7', 'SJ53', 'SJ52', '1054', '4426', '4404', '145', '2176']),
              'val': np.array(['758', '4406']),
              'test': np.array(['SJ65', 'SJ49', '741','748'])
          }
      ]


    # Define Venetoclax rotations with actual PDX group names
    venetoclax_rotations = [
        {
            'train': np.array(['SJ65', 'SJ7', '741', '4404', '748','SJ52', '1054', '4406', 'SJ49', '4426']),
            'val': np.array(['748', 'SJ53']),
            'test': np.array(['2176', '758', '145'])
        },
        {
            'train': np.array(['SJ65', 'SJ7', 'SJ49', '4406', '4404', '741', '758', '2176']),
            'val': np.array(['145', '1054']),
            'test': np.array(['748', 'SJ52', 'SJ53','4426'])
        },
        {
            'train': np.array(['SJ53', 'SJ7', 'SJ49', 'SJ52', '145', '1054', '748', '758']),
            'val': np.array(['4406', '2176']),
            'test': np.array(['4404', '741', 'SJ65'])
        },
        {
            'train': np.array(['2176', 'SJ53', 'SJ52', '4426', '4404', '741', '758','145','SJ7']),
            'val': np.array(['748', 'SJ65']),
            'test': np.array(['1054', 'SJ49', '4406'])
        }
    ]

    print(f"\nLoaded {len(dasatinib_rotations)} rotations for Dasatinib.")
    print(f"Loaded {len(venetoclax_rotations)} rotations for Venetoclax.")

    # Print a sample of the rotations for each drug
    sample_size = min(3, len(dasatinib_rotations))
    print(f"\nSample of {sample_size} Dasatinib rotations:")
    for i in range(sample_size):
        print(f"\nDasatinib Rotation {i+1}:")
        print(f"  Training PDX ({len(dasatinib_rotations[i]['train'])}): {', '.join(dasatinib_rotations[i]['train'])}")
        print(f"  Validation PDX ({len(dasatinib_rotations[i]['val'])}): {', '.join(dasatinib_rotations[i]['val'])}")
        print(f"  Testing PDX ({len(dasatinib_rotations[i]['test'])}): {', '.join(dasatinib_rotations[i]['test'])}")

    sample_size = min(3, len(venetoclax_rotations))
    print(f"\nSample of {sample_size} Venetoclax rotations:")
    for i in range(sample_size):
        print(f"\nVenetoclax Rotation {i+1}:")
        print(f"  Training PDX ({len(venetoclax_rotations[i]['train'])}): {', '.join(venetoclax_rotations[i]['train'])}")
        print(f"  Validation PDX ({len(venetoclax_rotations[i]['val'])}): {', '.join(venetoclax_rotations[i]['val'])}")
        print(f"  Testing PDX ({len(venetoclax_rotations[i]['test'])}): {', '.join(venetoclax_rotations[i]['test'])}")


    # Define the best parameters for each drug based on previous optimization
    dasatinib_params = {
        'n_estimators': 100,
        'learning_rate': 0.05,
        'max_depth': 6,
        'min_child_weight': 3,
        'gamma': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0
    }

    venetoclax_params = {
        'n_estimators': 100,
        'learning_rate': 0.05,
        'max_depth': 5,
        'min_child_weight': 3,
        'gamma': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0
    }

    # Prepare data for models
    X_das = pdx_df[dasatinib_features]
    y_dasatinib = pdx_df['Dasatinib Sensitivity']

    X_ven = pdx_df[venetoclax_features]
    y_venetoclax = pdx_df['Venetoclax Sensitivity']
    # Prepare for results collection
    cv_results = {
        'dasatinib': {
            'rotation_metrics': [],
            'avg_metrics': {}
        },
        'venetoclax': {
            'rotation_metrics': [],
            'avg_metrics': {}
        }
    }

    #-------------------------------------------------------------
    # CROSS-VALIDATION FOR DASATINIB
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ROTATIONAL CROSS-VALIDATION FOR DASATINIB")
    print("="*80)

    # Perform cross-validation for Dasatinib across all rotations
    for rot_idx, rotation in enumerate(dasatinib_rotations):
        rotation_name = f"Rotation {rot_idx+1}"
        print(f"\nProcessing {rotation_name} for Dasatinib...")

        # Get indices for train, validation, and test sets
        train_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['train'])].index
        val_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['val'])].index
        test_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['test'])].index

        print(f"Training samples: {len(train_indices)}")
        print(f"Validation samples: {len(val_indices)}")
        print(f"Test samples: {len(test_indices)}")
        # Extract data for this rotation
        X_train_rot = X_das.loc[train_indices]
        y_train_rot = y_dasatinib.loc[train_indices]
        X_val_rot = X_das.loc[val_indices]
        y_val_rot = y_dasatinib.loc[val_indices]
        X_test_rot = X_das.loc[test_indices]
        y_test_rot = y_dasatinib.loc[test_indices]

        # Train and evaluate model
        rot_result = train_and_evaluate_xgboost(
            X_train_rot, y_train_rot,
            X_val_rot, y_val_rot,
            X_test_rot, y_test_rot,
            X_das.columns.tolist(),
            drug_name=f"Dasatinib_{rotation_name}",
            k_best=30,
            xgb_params=dasatinib_params
        )

        # Store metrics
        cv_results['dasatinib']['rotation_metrics'].append({
            'rotation': rotation_name,
            'accuracy': rot_result['accuracy'],
            'roc_auc': rot_result['roc_auc'],
            'f1_score': rot_result['f1_score'],
            'precision': rot_result['precision'],
            'recall': rot_result['recall'],
            'train_groups': rotation['train'].tolist(),
            'val_groups': rotation['val'].tolist(),
            'test_groups': rotation['test'].tolist(),
            'selected_features': rot_result['selected_features']
        })
        # Store predictions and true labels for later analysis
        cv_results['dasatinib']['rotation_metrics'][-1]['y_test'] = y_test_rot.values
        cv_results['dasatinib']['rotation_metrics'][-1]['y_pred_proba'] = rot_result['y_pred_proba']
        # Generate plots
        plot_roc_curve(rot_result['y_test'], rot_result['y_pred_proba'],
                      f"Dasatinib_{rotation_name}", output_dirs)

        plot_confusion_matrix(rot_result['y_test'], rot_result['y_pred'],
                            f"Dasatinib_{rotation_name}", output_dirs)

        plot_probability_distribution(rot_result['y_test'], rot_result['y_pred_proba'],
                           f"Dasatinib_{rotation_name}", output_dirs,
                           test_indices=test_indices, pdx_df=pdx_df)

        plot_shap_analysis(rot_result['model'], rot_result['X_test_selected'],
                        rot_result['selected_features'], f"Dasatinib_{rotation_name}",
                        output_dirs, max_display=20)

    # Print cross-validation summary for Dasatinib
    print("\n" + "-"*50)
    print("Dasatinib Cross-Validation Summary:")
    print("-"*50)

    for rot_metric in cv_results['dasatinib']['rotation_metrics']:
        print(f"\n{rot_metric['rotation']}:")
        print(f"  Test groups: {', '.join(rot_metric['test_groups'])}")
        print(f"  Accuracy: {rot_metric['accuracy']:.4f}")
        print(f"  ROC AUC: {rot_metric['roc_auc']:.4f}")
        print(f"  F1 Score: {rot_metric['f1_score']:.4f}")
        print(f"  Precision: {rot_metric['precision']:.4f}")
        print(f"  Recall: {rot_metric['recall']:.4f}")
    # Calculate average performance across rotations
    avg_accuracy = np.mean([m['accuracy'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_roc_auc = np.mean([m['roc_auc'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_f1 = np.mean([m['f1_score'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_precision = np.mean([m['precision'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_recall = np.mean([m['recall'] for m in cv_results['dasatinib']['rotation_metrics']])

    # Store average metrics
    cv_results['dasatinib']['avg_metrics'] = {
        'accuracy': avg_accuracy,
        'roc_auc': avg_roc_auc,
        'f1_score': avg_f1,
        'precision': avg_precision,
        'recall': avg_recall
    }

    print("\nAverage Performance:")
    print(f"  Accuracy: {avg_accuracy:.4f}")
    print(f"  ROC AUC: {avg_roc_auc:.4f}")
    print(f"  F1 Score: {avg_f1:.4f}")
    print(f"  Precision: {avg_precision:.4f}")
    print(f"  Recall: {avg_recall:.4f}")

    #-------------------------------------------------------------
    # CROSS-VALIDATION FOR VENETOCLAX
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ROTATIONAL CROSS-VALIDATION FOR VENETOCLAX")
    print("="*80)

    # Perform cross-validation for Venetoclax across all rotations
    for rot_idx, rotation in enumerate(venetoclax_rotations):
        rotation_name = f"Rotation {rot_idx+1}"
        print(f"\nProcessing {rotation_name} for Venetoclax...")

        # Get indices for train, validation, and test sets
        train_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['train'])].index
        val_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['val'])].index
        test_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['test'])].index

        print(f"Training samples: {len(train_indices)}")
        print(f"Validation samples: {len(val_indices)}")
        print(f"Test samples: {len(test_indices)}")

        # Extract data for this rotation
        X_train_rot = X_ven.loc[train_indices]
        y_train_rot = y_venetoclax.loc[train_indices]
        X_val_rot = X_ven.loc[val_indices]
        y_val_rot = y_venetoclax.loc[val_indices]
        X_test_rot = X_ven.loc[test_indices]
        y_test_rot = y_venetoclax.loc[test_indices]

        # Train and evaluate model
        rot_result = train_and_evaluate_xgboost(
            X_train_rot, y_train_rot,
            X_val_rot, y_val_rot,
            X_test_rot, y_test_rot,
            X_ven.columns.tolist(),
            drug_name=f"Venetoclax_{rotation_name}",
            k_best=30,
            xgb_params=venetoclax_params
        )

        # Store metrics
        cv_results['venetoclax']['rotation_metrics'].append({
            'rotation': rotation_name,
            'accuracy': rot_result['accuracy'],
            'roc_auc': rot_result['roc_auc'],
            'f1_score': rot_result['f1_score'],
            'precision': rot_result['precision'],
            'recall': rot_result['recall'],
            'train_groups': rotation['train'].tolist(),
            'val_groups': rotation['val'].tolist(),
            'test_groups': rotation['test'].tolist(),
            'selected_features': rot_result['selected_features']
        })
        # Store predictions and true labels for later analysis
        cv_results['venetoclax']['rotation_metrics'][-1]['y_test'] = y_test_rot.values
        cv_results['venetoclax']['rotation_metrics'][-1]['y_pred_proba'] = rot_result['y_pred_proba']
        # Generate plots
        plot_roc_curve(rot_result['y_test'], rot_result['y_pred_proba'],
                      f"Venetoclax_{rotation_name}", output_dirs)

        plot_confusion_matrix(rot_result['y_test'], rot_result['y_pred'],
                             f"Venetoclax_{rotation_name}", output_dirs)

        plot_probability_distribution(rot_result['y_test'], rot_result['y_pred_proba'],
                           f"Venetoclax_{rotation_name}", output_dirs,
                           test_indices=test_indices, pdx_df=pdx_df)

        plot_shap_analysis(rot_result['model'], rot_result['X_test_selected'],
                         rot_result['selected_features'], f"Venetoclax_{rotation_name}",
                         output_dirs, max_display=20)
    # Print cross-validation summary for Venetoclax
    print("\n" + "-"*50)
    print("Venetoclax Cross-Validation Summary:")
    print("-"*50)

    for rot_metric in cv_results['venetoclax']['rotation_metrics']:
        print(f"\n{rot_metric['rotation']}:")
        print(f"  Test groups: {', '.join(rot_metric['test_groups'])}")
        print(f"  Accuracy: {rot_metric['accuracy']:.4f}")
        print(f"  ROC AUC: {rot_metric['roc_auc']:.4f}")
        print(f"  F1 Score: {rot_metric['f1_score']:.4f}")
        print(f"  Precision: {rot_metric['precision']:.4f}")
        print(f"  Recall: {rot_metric['recall']:.4f}")

    # Calculate average performance across rotations
    avg_accuracy = np.mean([m['accuracy'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_roc_auc = np.mean([m['roc_auc'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_f1 = np.mean([m['f1_score'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_precision = np.mean([m['precision'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_recall = np.mean([m['recall'] for m in cv_results['venetoclax']['rotation_metrics']])

    # Store average metrics
    cv_results['venetoclax']['avg_metrics'] = {
        'accuracy': avg_accuracy,
        'roc_auc': avg_roc_auc,
        'f1_score': avg_f1,
        'precision': avg_precision,
        'recall': avg_recall
    }

    print("\nAverage Performance:")
    print(f"  Accuracy: {avg_accuracy:.4f}")
    print(f"  ROC AUC: {avg_roc_auc:.4f}")
    print(f"  F1 Score: {avg_f1:.4f}")
    print(f"  Precision: {avg_precision:.4f}")
    print(f"  Recall: {avg_recall:.4f}")

    #-------------------------------------------------------------
    # FEATURE IMPORTANCE ANALYSIS
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("FEATURE IMPORTANCE ANALYSIS")
    print("="*80)

    # Analyze feature importance across rotations for each drug
    # Create dictionaries to store feature importance counts
    dasatinib_feature_counts = {}
    venetoclax_feature_counts = {}

    # Count how many times each feature was selected across rotations
    for rot_metrics in cv_results['dasatinib']['rotation_metrics']:
        for feature in rot_metrics['selected_features']:
            dasatinib_feature_counts[feature] = dasatinib_feature_counts.get(feature, 0) + 1

    for rot_metrics in cv_results['venetoclax']['rotation_metrics']:
        for feature in rot_metrics['selected_features']:
            venetoclax_feature_counts[feature] = venetoclax_feature_counts.get(feature, 0) + 1

    # Sort features by frequency
    dasatinib_top_features = sorted(dasatinib_feature_counts.items(), key=lambda x: x[1], reverse=True)
    venetoclax_top_features = sorted(venetoclax_feature_counts.items(), key=lambda x: x[1], reverse=True)

    # Print top consistent features (selected in all rotations)
    print("\nDasatinib features selected across all rotations:")
    for feature, count in dasatinib_top_features:
        if count == len(dasatinib_rotations):
            print(f"  - {feature}")

    print("\nVenetoclax features selected across all rotations:")
    for feature, count in venetoclax_top_features:
        if count == len(venetoclax_rotations):
            print(f"  - {feature}")

    # Print top 15 features by selection frequency
    print("\nTop 15 Dasatinib features by selection frequency:")
    for i, (feature, count) in enumerate(dasatinib_top_features[:15]):
        print(f"  {i+1}. {feature} (selected in {count}/{len(dasatinib_rotations)} rotations)")

    print("\nTop 15 Venetoclax features by selection frequency:")
    for i, (feature, count) in enumerate(venetoclax_top_features[:15]):
        print(f"  {i+1}. {feature} (selected in {count}/{len(venetoclax_rotations)} rotations)")
#-------------------------------------------------------------
    # COMPARATIVE ANALYSIS
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("COMPARATIVE ANALYSIS OF DRUGS")
    print("="*80)

    # Compare average cross-validation performance
    das_avg = cv_results['dasatinib']['avg_metrics']
    ven_avg = cv_results['venetoclax']['avg_metrics']

    print("\nCross-Validation Average Performance Comparison:")
    print("\nMetric     | Dasatinib | Venetoclax | Difference")
    print("-" * 50)
    print(f"Accuracy   | {das_avg['accuracy']:.4f}   | {ven_avg['accuracy']:.4f}    | {das_avg['accuracy'] - ven_avg['accuracy']:.4f}")
    print(f"ROC AUC    | {das_avg['roc_auc']:.4f}   | {ven_avg['roc_auc']:.4f}    | {das_avg['roc_auc'] - ven_avg['roc_auc']:.4f}")
    print(f"F1 Score   | {das_avg['f1_score']:.4f}   | {ven_avg['f1_score']:.4f}    | {das_avg['f1_score'] - ven_avg['f1_score']:.4f}")
    print(f"Precision  | {das_avg['precision']:.4f}   | {ven_avg['precision']:.4f}    | {das_avg['precision'] - ven_avg['precision']:.4f}")
    print(f"Recall     | {das_avg['recall']:.4f}   | {ven_avg['recall']:.4f}    | {das_avg['recall'] - ven_avg['recall']:.4f}")

    # Compare best rotation performance
    best_das = cv_results['dasatinib']['rotation_metrics'][best_dasatinib_rotation]
    best_ven = cv_results['venetoclax']['rotation_metrics'][best_venetoclax_rotation]

    print("\nBest Rotation Performance Comparison:")
    print("\nMetric     | Dasatinib | Venetoclax | Difference")
    print("-" * 50)
    print(f"Accuracy   | {best_das['accuracy']:.4f}   | {best_ven['accuracy']:.4f}    | {best_das['accuracy'] - best_ven['accuracy']:.4f}")
    print(f"ROC AUC    | {best_das['roc_auc']:.4f}   | {best_ven['roc_auc']:.4f}    | {best_das['roc_auc'] - best_ven['roc_auc']:.4f}")
    print(f"F1 Score   | {best_das['f1_score']:.4f}   | {best_ven['f1_score']:.4f}    | {best_das['f1_score'] - best_ven['f1_score']:.4f}")

    # Create visualizations for comparing best performance
    plt.figure(figsize=(12, 8))

    # Extract data for plotting
    metrics = ['accuracy', 'roc_auc', 'f1_score', 'precision', 'recall']
    dasatinib_values = [best_das[metric] for metric in metrics]
    venetoclax_values = [best_ven[metric] for metric in metrics]

    x = np.arange(len(metrics))
    width = 0.35

    plt.bar(x - width/2, dasatinib_values, width, label='Dasatinib (Best Rotation)')
    plt.bar(x + width/2, venetoclax_values, width, label='Venetoclax (Best Rotation)')

    plt.xlabel('Metric')
    plt.ylabel('Value')
    plt.title('Best Rotation Performance by Drug')
    plt.xticks(x, [m.replace('_', ' ').title() for m in metrics])
    plt.ylim(0, 1.1)
    plt.legend()
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    # Save the comparison chart
    plt.tight_layout()
    plt.savefig(os.path.join(output_dirs['plots_dir'], 'Best_Rotation_Performance_Comparison.svg'), dpi=1200)
    plt.close()

    #-------------------------------------------------------------
    # SAVE RESULTS
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("SAVING RESULTS")
    print("="*80)
    # Try to get Google Drive path if in Colab
    try:
        from google.colab import drive
        drive_mounted = True
        # Create a directory in Google Drive to save results
        gdrive_dir = '/content/drive/MyDrive/PDX_Analysis_Results/cv_results'
        if not os.path.exists(gdrive_dir):
            os.makedirs(gdrive_dir)
        output_file = os.path.join(gdrive_dir, 'pdx_drug_specific_rotation_cv_results.pkl')
    except (ImportError, ModuleNotFoundError):
        drive_mounted = False
        # Use local directory if not in Colab
        output_file = os.path.join(output_dirs['model_dir'], 'pdx_drug_specific_rotation_cv_results.pkl')

    # Prepare results for saving (without large model objects)
    final_results = {
        'dasatinib': {
            'rotation_metrics': cv_results['dasatinib']['rotation_metrics'],
            'avg_metrics': cv_results['dasatinib']['avg_metrics'],
            'top_features': dasatinib_top_features[:30],
            'optimal_rotation': optimal_rotation_info['best_dasatinib'],
            'top_rotations': optimal_rotation_info['top_dasatinib_rotations']
        },
        'venetoclax': {
            'rotation_metrics': cv_results['venetoclax']['rotation_metrics'],
            'avg_metrics': cv_results['venetoclax']['avg_metrics'],
            'top_features': venetoclax_top_features[:30],
            'optimal_rotation': optimal_rotation_info['best_venetoclax'],
            'top_rotations': optimal_rotation_info['top_venetoclax_rotations']
        },
        'metadata': {
            'dasatinib_rotations': [{
                'train': rotation['train'].tolist(),
                'val': rotation['val'].tolist(),
                'test': rotation['test'].tolist()
            } for rotation in dasatinib_rotations],
            'venetoclax_rotations': [{
                'train': rotation['train'].tolist(),
                'val': rotation['val'].tolist(),
                'test': rotation['test'].tolist()
            } for rotation in venetoclax_rotations],
            'date': pd.Timestamp.now().strftime('%Y-%m-%d')
        }
    }

    # Save results
    try:
        with open(output_file, 'wb') as f:
            pickle.dump(final_results, f)
        print(f"Results saved to {output_file}")
    except Exception as e:
        print(f"Error saving results: {str(e)}")

    # Create summary report
    report_path = os.path.join(output_dirs['plots_dir'], 'PDX_Drug_Specific_CV_Summary.pdf')
    print(f"Creating summary report at {report_path}")

    with PdfPages(report_path) as pdf:
        # Title page
        plt.figure(figsize=(11, 8.5))
        plt.text(0.5, 0.5, 'PDX-Specific Drug Sensitivity Prediction\nCross-Validation Summary Report',
                 horizontalalignment='center', verticalalignment='center', fontsize=24)
        plt.text(0.5, 0.3, f'Date: {pd.Timestamp.now().strftime("%Y-%m-%d")}',
                 horizontalalignment='center', verticalalignment='center', fontsize=14)
        plt.axis('off')
        pdf.savefig()
        plt.close()

        # Method description
        plt.figure(figsize=(11, 8.5))
        plt.axis('off')
        # Replace lines 3653-3657 in the report generation section with this code:

        # Replace the method_text section (around line 3652) with this correctly closed version:

        method_text = (
            "METHODOLOGY\n\n"
            f"This analysis evaluated separate rotation schemes for Dasatinib and Venetoclax models.\n\n"
            f"For each drug:\n"
            f"  - Generated {len(dasatinib_rotations)} distinct PDX rotations for Dasatinib\n"
            f"  - Generated {len(venetoclax_rotations)} distinct PDX rotations for Venetoclax\n"
            f"  - Each rotation used approximately {len(dasatinib_rotations[0]['train'])} PDX groups for training, "
            f"{len(dasatinib_rotations[0]['val'])} for validation, and {len(dasatinib_rotations[0]['test'])} for testing\n"
            f"  - Used drug-specific feature sets and model parameters\n"
            f"  - Identified optimal training/validation/testing splits for each drug separately\n\n"
            f"Drug-specific feature selection:\n"
            f"  - Dasatinib: LCK-related features and cell shape parameters\n"
            f"  - Venetoclax: BCL2-related features and cell shape parameters\n\n"
            f"Evaluation metrics: Accuracy, ROC AUC, F1 score, Precision, Recall"
        )
        plt.text(0.1, 0.9, method_text, fontsize=12, verticalalignment='top',
                 family='monospace', transform=plt.gca().transAxes)
        plt.title("Methodology", fontsize=16, y=0.98)
        pdf.savefig()
        plt.close()

        # Performance table
        plt.figure(figsize=(11, 8.5))
        plt.axis('off')

        # Get average and best metrics
        das_avg = cv_results['dasatinib']['avg_metrics']
        ven_avg = cv_results['venetoclax']['avg_metrics']
        best_das = cv_results['dasatinib']['rotation_metrics'][best_dasatinib_rotation]
        best_ven = cv_results['venetoclax']['rotation_metrics'][best_venetoclax_rotation]

        table_text = "PERFORMANCE SUMMARY\n\n"
        table_text += "DASATINIB:\n"
        table_text += f"  Average across all rotations:\n"
        table_text += f"    ROC AUC: {das_avg['roc_auc']:.4f}\n"
        table_text += f"    Accuracy: {das_avg['accuracy']:.4f}\n"
        table_text += f"    F1 Score: {das_avg['f1_score']:.4f}\n\n"

        table_text += f"  Best rotation (Rotation {best_dasatinib_rotation+1}):\n"
        table_text += f"    ROC AUC: {best_das['roc_auc']:.4f}\n"
        table_text += f"    Accuracy: {best_das['accuracy']:.4f}\n"
        table_text += f"    F1 Score: {best_das['f1_score']:.4f}\n\n"

        table_text += "VENETOCLAX:\n"
        table_text += f"  Average across all rotations:\n"
        table_text += f"    ROC AUC: {ven_avg['roc_auc']:.4f}\n"
        table_text += f"    Accuracy: {ven_avg['accuracy']:.4f}\n"
        table_text += f"    F1 Score: {ven_avg['f1_score']:.4f}\n\n"

        table_text += f"  Best rotation (Rotation {best_venetoclax_rotation+1}):\n"
        table_text += f"    ROC AUC: {best_ven['roc_auc']:.4f}\n"
        table_text += f"    Accuracy: {best_ven['accuracy']:.4f}\n"
        table_text += f"    F1 Score: {best_ven['f1_score']:.4f}\n"

        plt.text(0.1, 0.9, table_text, fontsize=12, verticalalignment='top',
                 family='monospace', transform=plt.gca().transAxes)
        plt.title("Performance Summary", fontsize=16, y=0.98)
        pdf.savefig()
        plt.close()

        # Feature importance page
        plt.figure(figsize=(11, 8.5))
        plt.axis('off')

        features_text = "TOP 10 FEATURES BY SELECTION FREQUENCY\n\n"
        features_text += "Dasatinib:\n"

        for i, (feature, count) in enumerate(dasatinib_top_features[:10]):
            features_text += f"  {i+1}. {feature} (selected in {count}/{len(dasatinib_rotations)} rotations)\n"

        features_text += "\nVenetoclax:\n"

        for i, (feature, count) in enumerate(venetoclax_top_features[:10]):
            features_text += f"  {i+1}. {feature} (selected in {count}/{len(venetoclax_rotations)} rotations)\n"

        plt.text(0.1, 0.9, features_text, fontsize=12, verticalalignment='top',
                 family='monospace', transform=plt.gca().transAxes)
        plt.title("Feature Importance Analysis", fontsize=16, y=0.98)
        pdf.savefig()
        plt.close()

        # Optimal rotation summary
        plt.figure(figsize=(11, 8.5))
        plt.axis('off')

        optimal_text = "OPTIMAL PDX ROTATIONS\n\n"

        optimal_text += "Best Dasatinib Rotation:\n"
        optimal_text += f"  Rotation {best_dasatinib_rotation+1} (ROC AUC: {dasatinib_rotation_ranks[0][1]:.4f})\n"
        optimal_text += f"  Training PDX: {', '.join(dasatinib_rotations[best_dasatinib_rotation]['train'])}\n"
        optimal_text += f"  Validation PDX: {', '.join(dasatinib_rotations[best_dasatinib_rotation]['val'])}\n"
        optimal_text += f"  Testing PDX: {', '.join(dasatinib_rotations[best_dasatinib_rotation]['test'])}\n\n"

        optimal_text += "Best Venetoclax Rotation:\n"
        optimal_text += f"  Rotation {best_venetoclax_rotation+1} (ROC AUC: {venetoclax_rotation_ranks[0][1]:.4f})\n"
        optimal_text += f"  Training PDX: {', '.join(venetoclax_rotations[best_venetoclax_rotation]['train'])}\n"
        optimal_text += f"  Validation PDX: {', '.join(venetoclax_rotations[best_venetoclax_rotation]['val'])}\n"
        optimal_text += f"  Testing PDX: {', '.join(venetoclax_rotations[best_venetoclax_rotation]['test'])}\n\n"

        # Check for any overlap in test PDX between the best rotations
        best_das_test = set(dasatinib_rotations[best_dasatinib_rotation]['test'])
        best_ven_test = set(venetoclax_rotations[best_venetoclax_rotation]['test'])
        common_test = best_das_test.intersection(best_ven_test)

        if common_test:
            optimal_text += f"Common Testing PDX in best rotations: {', '.join(common_test)}\n\n"
        else:
            optimal_text += "No common PDX groups in the test sets of best rotations.\n\n"

        plt.text(0.1, 0.9, optimal_text, fontsize=12, verticalalignment='top',
                 family='monospace', transform=plt.gca().transAxes)
        plt.title("Optimal PDX Rotations", fontsize=16, y=0.98)
        pdf.savefig()
        plt.close()

        # Conclusions page
        plt.figure(figsize=(11, 8.5))
        plt.axis('off')

        # Determine which drug performed better
        better_drug = "Dasatinib" if best_das['roc_auc'] > best_ven['roc_auc'] else "Venetoclax"

        conclusions_text = "KEY CONCLUSIONS\n\n"
        conclusions_text += f"1. Overall Performance:\n"
        conclusions_text += f"   {better_drug} showed better maximum performance with optimal PDX rotation.\n"
        conclusions_text += f"   Dasatinib best ROC AUC: {best_das['roc_auc']:.4f}\n"
        conclusions_text += f"   Venetoclax best ROC AUC: {best_ven['roc_auc']:.4f}\n\n"

        conclusions_text += f"2. PDX Group Selection:\n"
        conclusions_text += f"   Each drug benefits from different PDX groups for training and testing.\n"
        conclusions_text += f"   The optimal training/testing splits are drug-specific.\n\n"

        conclusions_text += f"3. Feature Importance:\n"
        conclusions_text += f"   Dasatinib prediction relies primarily on: LCK-related features and cell shape parameters.\n"
        conclusions_text += f"   Venetoclax prediction relies primarily on: BCL2-related features and cell shape parameters.\n\n"

        das_consistency = np.std([m['roc_auc'] for m in cv_results['dasatinib']['rotation_metrics']])
        ven_consistency = np.std([m['roc_auc'] for m in cv_results['venetoclax']['rotation_metrics']])
        more_consistent = "Dasatinib" if das_consistency < ven_consistency else "Venetoclax"

        conclusions_text += f"4. Rotation Sensitivity:\n"
        conclusions_text += f"   {more_consistent} models showed more consistent performance across different PDX rotations.\n"
        conclusions_text += f"   Dasatinib ROC AUC standard deviation: {das_consistency:.4f}\n"
        conclusions_text += f"   Venetoclax ROC AUC standard deviation: {ven_consistency:.4f}\n\n"

        conclusions_text += f"5. Recommendations:\n"
        conclusions_text += f"   - Use drug-specific PDX groupings for optimal predictive performance.\n"
        conclusions_text += f"   - Consider the identified optimal rotations when designing future experiments.\n"
        conclusions_text += f"   - When evaluating new PDX samples, apply the drug-specific optimal models.\n"

        plt.text(0.1, 0.9, conclusions_text, fontsize=12, verticalalignment='top',
                 family='monospace', transform=plt.gca().transAxes)
        plt.title("Key Conclusions", fontsize=16, y=0.98)
        pdf.savefig()
        plt.close()

    print(f"\nSummary report saved to {report_path}")
if __name__ == "__main__":
    results = main()
