#=====================================================================
MAIN FUNCTION WITH PDX-FOCUSED CROSS-VALIDATION
#=====================================================================

def main():
    start_time = time.time()

    # Try to mount Google Drive for Colab
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print("Google Drive mounted successfully")
        using_colab = True
    except (ImportError, ModuleNotFoundError):
        print("Not running in Colab or drive module not available")
        using_colab = False

    # Define output directories - SAVE TO GOOGLE DRIVE
    if using_colab:
        # Change this base path to your desired Google Drive folder
        base_drive_path = '/content/drive/MyDrive/PDX_Analysis_Results_New042025/'
    else:
        base_drive_path = './'  # Local path if not using Colab

    output_dirs = {
        'model_dir': os.path.join(base_drive_path, 'xgboost_pdx_cv'),
        'plots_dir': os.path.join(base_drive_path, 'plots_pdf'),
        'data_dir': os.path.join(base_drive_path, 'data_csv')
    }

    # Create all directories
    for dir_name, dir_path in output_dirs.items():
        create_output_directory(dir_path)

    # File path - Try to load from Google Drive if available
    if using_colab:
        # Change this path to your input file location on Drive
        file_path = '/content/drive/MyDrive/DMF_Pharmacotyping/data_combined_all_032725.csv'
    else:
        file_path = 'data_combined_all.csv'  # Local path

    # Load the data
    try:
        df = pd.read_csv(file_path)
        print(f"Dataset loaded with shape: {df.shape}")
    except FileNotFoundError:
        print(f"File not found at: {file_path}")
        return

    df['Group'] = df['Group'].astype(str)
    # Define cell line samples based on information
    cell_line_names = ['CEM', 'HSB', 'KOPT', 'RPMI8402', 'LOUCY', 'MOLT4', 'DND41']

    # Apply the function to determine sample types
    df['Sample_Type'] = df['Group'].apply(lambda x: determine_sample_type(x, cell_line_names))

    # Display counts of each sample type
    print("\nSample type distribution:")
    print(df['Sample_Type'].value_counts())

    # Filter to only PDX samples
    pdx_df = df[df['Sample_Type'] == 'PDX'].copy()
    print(f"\nPDX samples selected: {pdx_df.shape[0]} rows")

    # Get unique PDX groups
    pdx_groups = pdx_df['Group'].astype(str).unique()
    print(f"\nFound {len(pdx_groups)} unique PDX groups: {', '.join(pdx_groups)}")

    if len(pdx_groups) != 14:
        print(f"WARNING: Expected 14 PDX groups but found {len(pdx_groups)}. Will continue with available groups.")

    #-------------------------------------------------------------
    # ENHANCED FEATURE ENGINEERING
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ENHANCED FEATURE ENGINEERING")
    print("="*80)

    # Handle missing and infinite values
    pdx_df.replace([np.inf, -np.inf], np.nan, inplace=True)

    # Only handle missing values for categorical columns, leave numeric NaNs for XGBoost
    categorical_cols = pdx_df.select_dtypes(exclude=np.number).columns
    for col in categorical_cols:
        if pdx_df[col].isnull().any():
            pdx_df[col].fillna('Unknown', inplace=True)

    # Basic ratio features (keeping original implementation)
    pdx_df['pLCK_to_LCK_ratio'] = np.divide(
        pdx_df['Intensity_MeanIntensity_pLCK'].values,
        pdx_df['Intensity_MeanIntensity_LCK'].values,
        out=np.zeros_like(pdx_df['Intensity_MeanIntensity_pLCK'].values, dtype=float),
        where=pdx_df['Intensity_MeanIntensity_LCK'].values!=0
    )
    pdx_df['pBCL2_to_BCL2_ratio'] = np.divide(
        pdx_df['Intensity_MeanIntensity_pBCL2'].values,
        pdx_df['Intensity_MeanIntensity_BCL_2'].values,
        out=np.zeros_like(pdx_df['Intensity_MeanIntensity_pBCL2'].values, dtype=float),
        where=pdx_df['Intensity_MeanIntensity_BCL_2'].values!=0
    )

    # Enhanced features - log transformations (adding small constant to avoid log(0))
    pdx_df['log_pLCK'] = np.log1p(pdx_df['Intensity_MeanIntensity_pLCK'])
    pdx_df['log_LCK'] = np.log1p(pdx_df['Intensity_MeanIntensity_LCK'])
    pdx_df['log_pBCL2'] = np.log1p(pdx_df['Intensity_MeanIntensity_pBCL2'])
    pdx_df['log_BCL2'] = np.log1p(pdx_df['Intensity_MeanIntensity_BCL_2'])
    # Log ratios (can capture different patterns than direct ratios)
    pdx_df['log_pLCK_to_LCK_ratio'] = pdx_df['log_pLCK'] - pdx_df['log_LCK']
    pdx_df['log_pBCL2_to_BCL2_ratio'] = pdx_df['log_pBCL2'] - pdx_df['log_BCL2']

    # Square and square root transformations to capture non-linear relationships
    pdx_df['pLCK_squared'] = np.square(pdx_df['Intensity_MeanIntensity_pLCK'])
    pdx_df['pBCL2_squared'] = np.square(pdx_df['Intensity_MeanIntensity_pBCL2'])
    pdx_df['pLCK_sqrt'] = np.sqrt(np.maximum(0, pdx_df['Intensity_MeanIntensity_pLCK']))
    pdx_df['pBCL2_sqrt'] = np.sqrt(np.maximum(0, pdx_df['Intensity_MeanIntensity_pBCL2']))

    # Z-scores for pLCK and pBCL2 within each PDX group
    for group in pdx_df['Group'].unique():
        group_mask = pdx_df['Group'] == group
        if sum(group_mask) > 1:  # Only standardize if we have multiple samples
            pdx_df.loc[group_mask, 'pLCK_zscore'] = safe_standardize(pdx_df.loc[group_mask, 'Intensity_MeanIntensity_pLCK'])
            pdx_df.loc[group_mask, 'pBCL2_zscore'] = safe_standardize(pdx_df.loc[group_mask, 'Intensity_MeanIntensity_pBCL2'])

    # Fill any missing z-scores with 0 (representing the mean)
    if 'pLCK_zscore' not in pdx_df.columns:
        pdx_df['pLCK_zscore'] = 0
    else:
        pdx_df['pLCK_zscore'].fillna(0, inplace=True)

    if 'pBCL2_zscore' not in pdx_df.columns:
        pdx_df['pBCL2_zscore'] = 0
    else:
        pdx_df['pBCL2_zscore'].fillna(0, inplace=True)
    # Create interaction features between key proteins and important shape features
    # First, identify top shape features that might interact with protein markers
    shape_features = [col for col in pdx_df.columns if 'AreaShape' in col]

    # Select a subset of shape features to avoid feature explosion
    key_shape_features = [
        'AreaShape_Area', 'AreaShape_Perimeter',
        'AreaShape_FormFactor', 'AreaShape_Eccentricity',
        'AreaShape_Solidity', 'AreaShape_Extent'
    ]

    # Filter to only use shape features that exist in the data
    key_shape_features = [f for f in key_shape_features if f in pdx_df.columns]

    # Create interaction features between key proteins and shape features
    for shape_feat in key_shape_features:
        if shape_feat in pdx_df.columns:
            # For pLCK
            pdx_df[f'pLCK_x_{shape_feat}'] = pdx_df['Intensity_MeanIntensity_pLCK'] * pdx_df[shape_feat]
            pdx_df[f'pLCK_ratio_x_{shape_feat}'] = pdx_df['pLCK_to_LCK_ratio'] * pdx_df[shape_feat]

            # For pBCL2
            pdx_df[f'pBCL2_x_{shape_feat}'] = pdx_df['Intensity_MeanIntensity_pBCL2'] * pdx_df[shape_feat]
            pdx_df[f'pBCL2_ratio_x_{shape_feat}'] = pdx_df['pBCL2_to_BCL2_ratio'] * pdx_df[shape_feat]

    # Replace any infinity values with NaN
    pdx_df.replace([np.inf, -np.inf], np.nan, inplace=True)
    # Define clean feature sets for each drug (no cross-contamination)
    lck_features_clean = [col for col in pdx_df.columns if 'LCK' in col.upper() and 'BCL' not in col.upper()]

    # Enhanced LCK features - only include those related to LCK not BCL2
    lck_enhanced_features_clean = [
        col for col in [
            'log_pLCK', 'log_LCK', 'log_pLCK_to_LCK_ratio',
            'pLCK_squared', 'pLCK_sqrt', 'pLCK_zscore', 'pLCK_to_LCK_ratio'
        ] if col in pdx_df.columns
    ]

    # LCK interaction features - only those related to LCK not BCL2
    lck_interaction_features_clean = [
        col for col in pdx_df.columns
        if ('pLCK_x_' in col or 'pLCK_ratio_x_' in col) and 'BCL' not in col.upper()
    ]

    # BCL2/pBCL2 features and shape features for Venetoclax - exclude LCK features
    bcl2_features_clean = [col for col in pdx_df.columns if ('BCL' in col.upper() or 'pBCL2' in col) and 'LCK' not in col.upper()]

    # Enhanced BCL2 features - only include those related to BCL2 not LCK
    bcl2_enhanced_features_clean = [
        col for col in [
            'log_pBCL2', 'log_BCL2', 'log_pBCL2_to_BCL2_ratio',
            'pBCL2_squared', 'pBCL2_sqrt', 'pBCL2_zscore', 'pBCL2_to_BCL2_ratio'
        ] if col in pdx_df.columns
    ]

    # BCL2 interaction features - only those related to BCL2 not LCK
    bcl2_interaction_features_clean = [
        col for col in pdx_df.columns
        if ('pBCL2_x_' in col or 'pBCL2_ratio_x_' in col) and 'LCK' not in col.upper()
    ]
    # Shape features remain the same for both
    shape_features = [col for col in pdx_df.columns if 'AreaShape' in col]

    # Final clean feature sets for each drug (no cross-contamination)
    dasatinib_features = list(set(lck_features_clean + lck_enhanced_features_clean + lck_interaction_features_clean + shape_features))
    from collections import Counter
    dups = [item for item, count in Counter(dasatinib_features).items() if count > 1]
    if dups:
        print(f"WARNING: Duplicate column names in Dasatinib features: {dups}")

    bcl2_in_dasatinib = [f for f in dasatinib_features if 'BCL' in f.upper() or 'pBCL2' in f]
    if bcl2_in_dasatinib:
        print(f"WARNING: BCL2-related features found in Dasatinib features: {bcl2_in_dasatinib}")
        print("Removing these BCL2-related features from Dasatinib feature set")
        dasatinib_features = [f for f in dasatinib_features if f not in bcl2_in_dasatinib]
        print(f"Updated Dasatinib feature count: {len(dasatinib_features)}")

    print(f"\nNumber of features for Dasatinib prediction (after cleaning): {len(dasatinib_features)}")
    print(f"Number of features for Venetoclax prediction (after cleaning): {len(venetoclax_features)}")

    # Print a few examples of each feature set to verify
    print("\nSample Dasatinib features:")
    for feat in sorted(dasatinib_features)[:10]:
        print(f"  - {feat}")

    print("\nSample Venetoclax features:")
    for feat in sorted(venetoclax_features)[:10]:
        print(f"  - {feat}")
#-------------------------------------------------------------
    # DATA SPLITTING FOR PDX ROTATIONAL CROSS-VALIDATION
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("PDX ROTATIONAL CROSS-VALIDATION SETUP")
    print("="*80)

    # Define the sampling strategy for PDX groups for both drugs separately

    # Make sure we have enough PDX groups
    if len(pdx_groups) < 14:
        print(f"WARNING: Not enough PDX groups (found {len(pdx_groups)}, need 14). Will adjust rotation accordingly.")

    # Define custom PDX rotations for both drugs based on the provided information
    print("\nManually setting up predefined PDX rotations for each drug...")

    # Define Dasatinib rotations with actual PDX group names
    dasatinib_rotations = [
          {
              'train': np.array(['SJ65', 'SJ49', 'SJ53', 'SJ52', '1054', '145', '741', '748', '4406']),
              'val': np.array(['SJ7', '4426']),
              'test': np.array(['758', '2176', '4404'])
          },
          {
              'train': np.array(['SJ65', 'SJ49', 'SJ52', '4426', '4404', '4406', '741', '758', '2176']),
              'val': np.array(['145', '748']),
              'test': np.array(['SJ7', 'SJ53', '1054'])
          },
          {
              'train': np.array(['SJ65', 'SJ53', '1054', '4404', 'SJ49', '748', '758', '2176']),
              'val': np.array(['SJ7', '741']),
              'test': np.array(['145', '4406', 'SJ52','4426'])
          },
          {
              'train': np.array(['SJ7', 'SJ53', 'SJ52', '1054', '4426', '4404', '145', '2176']),
              'val': np.array(['758', '4406']),
              'test': np.array(['SJ65', 'SJ49', '741','748'])
          }
      ]


    # Define Venetoclax rotations with actual PDX group names
    venetoclax_rotations = [
        {
            'train': np.array(['SJ65', 'SJ7', '741', '4404', '748','SJ52', '1054', '4406', 'SJ49', '4426']),
            'val': np.array(['748', 'SJ53']),
            'test': np.array(['2176', '758', '145'])
        },
        {
            'train': np.array(['SJ65', 'SJ7', 'SJ49', '4406', '4404', '741', '758', '2176']),
            'val': np.array(['145', '1054']),
            'test': np.array(['748', 'SJ52', 'SJ53','4426'])
        },
        {
            'train': np.array(['SJ53', 'SJ7', 'SJ49', 'SJ52', '145', '1054', '748', '758']),
            'val': np.array(['4406', '2176']),
            'test': np.array(['4404', '741', 'SJ65'])
        },
        {
            'train': np.array(['2176', 'SJ53', 'SJ52', '4426', '4404', '741', '758','145','SJ7']),
            'val': np.array(['748', 'SJ65']),
            'test': np.array(['1054', 'SJ49', '4406'])
        }
    ]

    print(f"\nLoaded {len(dasatinib_rotations)} rotations for Dasatinib.")
    print(f"Loaded {len(venetoclax_rotations)} rotations for Venetoclax.")

    # Print a sample of the rotations for each drug
    sample_size = min(3, len(dasatinib_rotations))
    print(f"\nSample of {sample_size} Dasatinib rotations:")
    for i in range(sample_size):
        print(f"\nDasatinib Rotation {i+1}:")
        print(f"  Training PDX ({len(dasatinib_rotations[i]['train'])}): {', '.join(dasatinib_rotations[i]['train'])}")
        print(f"  Validation PDX ({len(dasatinib_rotations[i]['val'])}): {', '.join(dasatinib_rotations[i]['val'])}")
        print(f"  Testing PDX ({len(dasatinib_rotations[i]['test'])}): {', '.join(dasatinib_rotations[i]['test'])}")

    sample_size = min(3, len(venetoclax_rotations))
    print(f"\nSample of {sample_size} Venetoclax rotations:")
    for i in range(sample_size):
        print(f"\nVenetoclax Rotation {i+1}:")
        print(f"  Training PDX ({len(venetoclax_rotations[i]['train'])}): {', '.join(venetoclax_rotations[i]['train'])}")
        print(f"  Validation PDX ({len(venetoclax_rotations[i]['val'])}): {', '.join(venetoclax_rotations[i]['val'])}")
        print(f"  Testing PDX ({len(venetoclax_rotations[i]['test'])}): {', '.join(venetoclax_rotations[i]['test'])}")


    # Define the best parameters for each drug based on previous optimization
    dasatinib_params = {
        'n_estimators': 100,
        'learning_rate': 0.05,
        'max_depth': 6,
        'min_child_weight': 3,
        'gamma': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0
    }

    venetoclax_params = {
        'n_estimators': 100,
        'learning_rate': 0.05,
        'max_depth': 5,
        'min_child_weight': 3,
        'gamma': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0
    }

    # Prepare data for models
    X_das = pdx_df[dasatinib_features]
    y_dasatinib = pdx_df['Dasatinib Sensitivity']

    X_ven = pdx_df[venetoclax_features]
    y_venetoclax = pdx_df['Venetoclax Sensitivity']
    # Prepare for results collection
    cv_results = {
        'dasatinib': {
            'rotation_metrics': [],
            'avg_metrics': {}
        },
        'venetoclax': {
            'rotation_metrics': [],
            'avg_metrics': {}
        }
    }

    #-------------------------------------------------------------
    # CROSS-VALIDATION FOR DASATINIB
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ROTATIONAL CROSS-VALIDATION FOR DASATINIB")
    print("="*80)

    # Perform cross-validation for Dasatinib across all rotations
    for rot_idx, rotation in enumerate(dasatinib_rotations):
        rotation_name = f"Rotation {rot_idx+1}"
        print(f"\nProcessing {rotation_name} for Dasatinib...")

        # Get indices for train, validation, and test sets
        train_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['train'])].index
        val_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['val'])].index
        test_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['test'])].index

        print(f"Training samples: {len(train_indices)}")
        print(f"Validation samples: {len(val_indices)}")
        print(f"Test samples: {len(test_indices)}")
        # Extract data for this rotation
        X_train_rot = X_das.loc[train_indices]
        y_train_rot = y_dasatinib.loc[train_indices]
        X_val_rot = X_das.loc[val_indices]
        y_val_rot = y_dasatinib.loc[val_indices]
        X_test_rot = X_das.loc[test_indices]
        y_test_rot = y_dasatinib.loc[test_indices]

        # Train and evaluate model
        rot_result = train_and_evaluate_xgboost(
            X_train_rot, y_train_rot,
            X_val_rot, y_val_rot,
            X_test_rot, y_test_rot,
            X_das.columns.tolist(),
            drug_name=f"Dasatinib_{rotation_name}",
            k_best=30,
            xgb_params=dasatinib_params
        )

        # Store metrics
        cv_results['dasatinib']['rotation_metrics'].append({
            'rotation': rotation_name,
            'accuracy': rot_result['accuracy'],
            'roc_auc': rot_result['roc_auc'],
            'f1_score': rot_result['f1_score'],
            'precision': rot_result['precision'],
            'recall': rot_result['recall'],
            'train_groups': rotation['train'].tolist(),
            'val_groups': rotation['val'].tolist(),
            'test_groups': rotation['test'].tolist(),
            'selected_features': rot_result['selected_features']
        })
        # Store predictions and true labels for later analysis
        cv_results['dasatinib']['rotation_metrics'][-1]['y_test'] = y_test_rot.values
        cv_results['dasatinib']['rotation_metrics'][-1]['y_pred_proba'] = rot_result['y_pred_proba']
        # Generate plots
        plot_roc_curve(rot_result['y_test'], rot_result['y_pred_proba'],
                      f"Dasatinib_{rotation_name}", output_dirs)

        plot_confusion_matrix(rot_result['y_test'], rot_result['y_pred'],
                            f"Dasatinib_{rotation_name}", output_dirs)

        plot_probability_distribution(rot_result['y_test'], rot_result['y_pred_proba'],
                           f"Dasatinib_{rotation_name}", output_dirs,
                           test_indices=test_indices, pdx_df=pdx_df)

        plot_shap_analysis(rot_result['model'], rot_result['X_test_selected'],
                        rot_result['selected_features'], f"Dasatinib_{rotation_name}",
                        output_dirs, max_display=20)

    # Print cross-validation summary for Dasatinib
    print("\n" + "-"*50)
    print("Dasatinib Cross-Validation Summary:")
    print("-"*50)

    for rot_metric in cv_results['dasatinib']['rotation_metrics']:
        print(f"\n{rot_metric['rotation']}:")
        print(f"  Test groups: {', '.join(rot_metric['test_groups'])}")
        print(f"  Accuracy: {rot_metric['accuracy']:.4f}")
        print(f"  ROC AUC: {rot_metric['roc_auc']:.4f}")
        print(f"  F1 Score: {rot_metric['f1_score']:.4f}")
        print(f"  Precision: {rot_metric['precision']:.4f}")
        print(f"  Recall: {rot_metric['recall']:.4f}")
    # Calculate average performance across rotations
    avg_accuracy = np.mean([m['accuracy'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_roc_auc = np.mean([m['roc_auc'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_f1 = np.mean([m['f1_score'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_precision = np.mean([m['precision'] for m in cv_results['dasatinib']['rotation_metrics']])
    avg_recall = np.mean([m['recall'] for m in cv_results['dasatinib']['rotation_metrics']])

    # Store average metrics
    cv_results['dasatinib']['avg_metrics'] = {
        'accuracy': avg_accuracy,
        'roc_auc': avg_roc_auc,
        'f1_score': avg_f1,
        'precision': avg_precision,
        'recall': avg_recall
    }

    print("\nAverage Performance:")
    print(f"  Accuracy: {avg_accuracy:.4f}")
    print(f"  ROC AUC: {avg_roc_auc:.4f}")
    print(f"  F1 Score: {avg_f1:.4f}")
    print(f"  Precision: {avg_precision:.4f}")
    print(f"  Recall: {avg_recall:.4f}")

    #-------------------------------------------------------------
    # CROSS-VALIDATION FOR VENETOCLAX
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("ROTATIONAL CROSS-VALIDATION FOR VENETOCLAX")
    print("="*80)

    # Perform cross-validation for Venetoclax across all rotations
    for rot_idx, rotation in enumerate(venetoclax_rotations):
        rotation_name = f"Rotation {rot_idx+1}"
        print(f"\nProcessing {rotation_name} for Venetoclax...")

        # Get indices for train, validation, and test sets
        train_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['train'])].index
        val_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['val'])].index
        test_indices = pdx_df[pdx_df['Group'].astype(str).isin(rotation['test'])].index

        print(f"Training samples: {len(train_indices)}")
        print(f"Validation samples: {len(val_indices)}")
        print(f"Test samples: {len(test_indices)}")

        # Extract data for this rotation
        X_train_rot = X_ven.loc[train_indices]
        y_train_rot = y_venetoclax.loc[train_indices]
        X_val_rot = X_ven.loc[val_indices]
        y_val_rot = y_venetoclax.loc[val_indices]
        X_test_rot = X_ven.loc[test_indices]
        y_test_rot = y_venetoclax.loc[test_indices]

        # Train and evaluate model
        rot_result = train_and_evaluate_xgboost(
            X_train_rot, y_train_rot,
            X_val_rot, y_val_rot,
            X_test_rot, y_test_rot,
            X_ven.columns.tolist(),
            drug_name=f"Venetoclax_{rotation_name}",
            k_best=30,
            xgb_params=venetoclax_params
        )

        # Store metrics
        cv_results['venetoclax']['rotation_metrics'].append({
            'rotation': rotation_name,
            'accuracy': rot_result['accuracy'],
            'roc_auc': rot_result['roc_auc'],
            'f1_score': rot_result['f1_score'],
            'precision': rot_result['precision'],
            'recall': rot_result['recall'],
            'train_groups': rotation['train'].tolist(),
            'val_groups': rotation['val'].tolist(),
            'test_groups': rotation['test'].tolist(),
            'selected_features': rot_result['selected_features']
        })
        # Store predictions and true labels for later analysis
        cv_results['venetoclax']['rotation_metrics'][-1]['y_test'] = y_test_rot.values
        cv_results['venetoclax']['rotation_metrics'][-1]['y_pred_proba'] = rot_result['y_pred_proba']
        # Generate plots
        plot_roc_curve(rot_result['y_test'], rot_result['y_pred_proba'],
                      f"Venetoclax_{rotation_name}", output_dirs)

        plot_confusion_matrix(rot_result['y_test'], rot_result['y_pred'],
                             f"Venetoclax_{rotation_name}", output_dirs)

        plot_probability_distribution(rot_result['y_test'], rot_result['y_pred_proba'],
                           f"Venetoclax_{rotation_name}", output_dirs,
                           test_indices=test_indices, pdx_df=pdx_df)

        plot_shap_analysis(rot_result['model'], rot_result['X_test_selected'],
                         rot_result['selected_features'], f"Venetoclax_{rotation_name}",
                         output_dirs, max_display=20)
    # Print cross-validation summary for Venetoclax
    print("\n" + "-"*50)
    print("Venetoclax Cross-Validation Summary:")
    print("-"*50)

    for rot_metric in cv_results['venetoclax']['rotation_metrics']:
        print(f"\n{rot_metric['rotation']}:")
        print(f"  Test groups: {', '.join(rot_metric['test_groups'])}")
        print(f"  Accuracy: {rot_metric['accuracy']:.4f}")
        print(f"  ROC AUC: {rot_metric['roc_auc']:.4f}")
        print(f"  F1 Score: {rot_metric['f1_score']:.4f}")
        print(f"  Precision: {rot_metric['precision']:.4f}")
        print(f"  Recall: {rot_metric['recall']:.4f}")

    # Calculate average performance across rotations
    avg_accuracy = np.mean([m['accuracy'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_roc_auc = np.mean([m['roc_auc'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_f1 = np.mean([m['f1_score'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_precision = np.mean([m['precision'] for m in cv_results['venetoclax']['rotation_metrics']])
    avg_recall = np.mean([m['recall'] for m in cv_results['venetoclax']['rotation_metrics']])

    # Store average metrics
    cv_results['venetoclax']['avg_metrics'] = {
        'accuracy': avg_accuracy,
        'roc_auc': avg_roc_auc,
        'f1_score': avg_f1,
        'precision': avg_precision,
        'recall': avg_recall
    }

    print("\nAverage Performance:")
    print(f"  Accuracy: {avg_accuracy:.4f}")
    print(f"  ROC AUC: {avg_roc_auc:.4f}")
    print(f"  F1 Score: {avg_f1:.4f}")
    print(f"  Precision: {avg_precision:.4f}")
    print(f"  Recall: {avg_recall:.4f}")

    #-------------------------------------------------------------
    # FEATURE IMPORTANCE ANALYSIS
    #-------------------------------------------------------------
    print("\n" + "="*80)
    print("FEATURE IMPORTANCE ANALYSIS")
    print("="*80)

    # Analyze feature importance across rotations for each drug
    # Create dictionaries to store feature importance counts
    dasatinib_feature_counts = {}
    venetoclax_feature_counts = {}

    # Count how many times each feature was selected across rotations
    for rot_metrics in cv_results['dasatinib']['rotation_metrics']:
        for feature in rot_metrics['selected_features']:
            dasatinib_feature_counts[feature] = dasatinib_feature_counts.get(feature, 0) + 1

    for rot_metrics in cv_results['venetoclax']['rotation_metrics']:
        for feature in rot_metrics['selected_features']:
            venetoclax_feature_counts[feature] = venetoclax_feature_counts.get(feature, 0) + 1

    # Sort features by frequency
    dasatinib_top_features = sorted(dasatinib_feature_counts.items(), key=lambda x: x[1], reverse=True)
    venetoclax_top_features = sorted(venetoclax_feature_counts.items(), key=lambda x: x[1], reverse=True)

    # Print top consistent features (selected in all rotations)
    print("\nDasatinib features selected across all rotations:")
    for feature, count in dasatinib_top_features:
        if count == len(dasatinib_rotations):
            print(f"  - {feature}")

    print("\nVenetoclax features selected across all rotations:")
    for feature, count in venetoclax_top_features:
        if count == len(venetoclax_rotations):
            print(f"  - {feature}")

    # Print top 15 features by selection frequency
    print("\nTop 15 Dasatinib features by selection frequency:")
    for i, (feature, count) in enumerate(dasatinib_top_features[:15]):
        print(f"  {i+1}. {feature} (selected in {count}/{len(dasatinib_rotations)} rotations)")

    print("\nTop 15 Venetoclax features by selection frequency:")
    for i, (feature, count) in enumerate(venetoclax_top_features[:15]):
        print(f"  {i+1}. {feature} (selected in {count}/{len(venetoclax_rotations)} rotations)")
